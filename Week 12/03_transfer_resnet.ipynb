{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# for importing data\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBSQO5HB6Kje"
   },
   "outputs": [],
   "source": [
    "# use GPU if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HOkOefftqyg"
   },
   "source": [
    "# Import a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet demonstrates the process of preparing the STL10 dataset for training and evaluation with a model like ResNet, which requires specific normalization values. It involves defining transformations to normalize the images and loading the dataset with these transformations applied. Here's a detailed explanation of the steps involved:\n",
    "\n",
    "### Transformations\n",
    "- **ToTensor()**: Converts the images to PyTorch tensors and scales the pixel values to the range [0, 1].\n",
    "- **Normalize()**: Applies normalization to the tensor images using mean and standard deviation values specific to the ResNet model. These values ([0.485, 0.456, 0.406] for the mean and [0.229, 0.224, 0.225] for the standard deviation) adjust the pixel values to match the distribution expected by ResNet, which is not in the range of [-1, 1].\n",
    "\n",
    "### Dataset Loading with Transformations\n",
    "- **STL10 Dataset**: The STL10 dataset is loaded for both training (`split='train'`) and testing (`split='test'`) purposes. The `transform` parameter ensures that all loaded images are processed according to the defined transformations.\n",
    "- The dataset is stored locally in the `'./data'` directory, and `download=True` allows automatic downloading if the data is not already present.\n",
    "\n",
    "### DataLoader Creation\n",
    "- **Training DataLoader**: A DataLoader for the training set is created with a specified `batch_size` of 32, `shuffle=True` to randomize the order of the images, promoting model generalization, and `drop_last=True` to discard the last incomplete batch for consistent batch sizes.\n",
    "- **Testing DataLoader**: The test set DataLoader uses a larger batch size of 256, optimizing for evaluation speed. Shuffling is not necessary for evaluation, so it is omitted.\n",
    "\n",
    "### Utility and Implications\n",
    "This setup ensures that the STL10 dataset is ready for use with models pre-trained with specific normalization parameters, like ResNet. The normalization step is crucial for matching the input distribution used during the original training of the model, affecting both the model's learning efficiency and its performance on new data.\n",
    "\n",
    "This approach exemplifies a critical preprocessing step in adapting datasets for use with specific models, highlighting the importance of understanding the expected input format and distribution for pre-trained neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1huHlhc4gnE"
   },
   "outputs": [],
   "source": [
    "### Note: resnet is trained for images in a specific range (NOT [-1,1]).\n",
    "#         That changes the mean/std normalization values in the transform.\n",
    "\n",
    "# transformations\n",
    "transform = T.Compose([ T.ToTensor(), # normalizes to range [0,1]\n",
    "                        T.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]) # further normalization\n",
    "                       ])\n",
    "\n",
    "# import the data and simultaneously apply the transform\n",
    "trainset = torchvision.datasets.STL10(root='./data', download=True, split='train', transform=transform)\n",
    "testset  = torchvision.datasets.STL10(root='./data', download=True, split='test',  transform=transform)\n",
    "\n",
    "# transform to dataloaders\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(trainset,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(testset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYwGTs2bxIjU"
   },
   "outputs": [],
   "source": [
    "# check out the shape of the datasets\n",
    "print('Data shapes (train/test):')\n",
    "print( trainset.data.shape )\n",
    "print( testset.data.shape )\n",
    "\n",
    "# and the range of pixel intensity values\n",
    "print('\\nData value range:')\n",
    "print( (np.min(trainset.data),np.max(trainset.data)) )\n",
    "\n",
    "# the unique categories\n",
    "print('\\nData categories:')\n",
    "print( trainset.classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJ4PjMSr4hPo"
   },
   "outputs": [],
   "source": [
    "# Uh oh! It looks like the images are the wrong dimensions!\n",
    "# They need to be 3x96x96\n",
    "# And they are not normalized!\n",
    "\n",
    "# but...\n",
    "X,y = next(iter(train_loader))\n",
    "\n",
    "# try again\n",
    "print('Data shapes (train/test):')\n",
    "print( X.data.shape )\n",
    "\n",
    "# and the range of pixel intensity values\n",
    "print('\\nData value range:')\n",
    "print( (torch.min(X.data),torch.max(X.data)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xk_A-XJAismr"
   },
   "outputs": [],
   "source": [
    "# histogram of the data\n",
    "plt.hist(X.data.numpy().flatten(),100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMpyFzF-d95B"
   },
   "outputs": [],
   "source": [
    "# inspect a few random images\n",
    "\n",
    "fig,axs = plt.subplots(4,4,figsize=(10,10))\n",
    "\n",
    "for (i,ax) in enumerate(axs.flatten()):\n",
    "\n",
    "  # extract that image (need to transpose it back to 32x32x3)\n",
    "  pic = X.data[i].numpy().transpose((1,2,0))\n",
    "  pic = pic-np.min(pic) # undo normalization\n",
    "  pic = pic/np.max(pic)\n",
    "  \n",
    "  # and its label\n",
    "  label = trainset.classes[y[i]]\n",
    "\n",
    "  # and show!\n",
    "  ax.imshow(pic)\n",
    "  ax.text(0,0,label,ha='left',va='top',fontweight='bold',color='k',backgroundcolor='y')\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXVi3dSWIGK2"
   },
   "source": [
    "# Import and inspect the resnet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet provides an updated method for instantiating a pre-trained ResNet18 model using PyTorch's torchvision library. This update reflects changes in the torchvision API, ensuring compatibility with the latest versions. Here's an overview of the process:\n",
    "\n",
    "### Deprecated Method\n",
    "- The original method for loading a pre-trained ResNet18 model (`torchvision.models.resnet18(pretrained=True)`) is mentioned as being deprecated. This method was straightforward, directly specifying the `pretrained=True` parameter to load the model with weights trained on ImageNet.\n",
    "\n",
    "### Updated Approach\n",
    "- **Weights Specification**: The new approach involves explicitly specifying the weights for the ResNet18 model using `torchvision.models.ResNet18_Weights.DEFAULT`. This method allows for more granular control over which pre-trained weights to use, accommodating scenarios where multiple versions or training configurations are available.\n",
    "- **Model Instantiation**: With the desired weights specified, the ResNet18 model is instantiated by passing the `weights` argument to `torchvision.models.resnet18()`. This ensures that the model is initialized with the specified pre-trained weights, ready for use in downstream tasks.\n",
    "\n",
    "### Implications and Utility\n",
    "- This update to the model loading process reflects PyTorch's evolving API and its efforts to provide more flexible and clear mechanisms for working with pre-trained models. By explicitly specifying weights, users gain the ability to choose from a variety of pre-trained configurations, enhancing the model's versatility for various applications.\n",
    "- Mention of the Q&A section suggests that further details and clarifications regarding this update can be found there, potentially addressing common questions and providing additional context for the changes.\n",
    "\n",
    "Overall, this code snippet demonstrates adherence to best practices in leveraging pre-trained models within PyTorch, ensuring that developers can take full advantage of the latest features and improvements in the torchvision library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLIQkY3WIlGX"
   },
   "outputs": [],
   "source": [
    "# The following line was recorded in the video, but is now depreciated. See also Q&A.\n",
    "# resnet = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# You can use the following instead. \n",
    "weights = torchvision.models.ResNet18_Weights.DEFAULT\n",
    "resnet = torchvision.models.resnet18(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7jb3M2LIlJ3"
   },
   "outputs": [],
   "source": [
    "# let's inspect this network\n",
    "resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet uses the `torchsummary` library to display a comprehensive summary of a pre-trained ResNet18 model (`resnet`) that has been adapted for use with images of size 96x96 pixels with 3 color channels (RGB). This functionality is particularly useful for understanding the architecture, including the number of parameters and the output size at each layer of the network. Here's a breakdown of how it works:\n",
    "\n",
    "### Overview\n",
    "- **Importing `summary` Function**: The `summary` function from the `torchsummary` package is imported. This function provides a detailed overview of a model's architecture in a concise and readable format.\n",
    "- **Model Preparation**: The ResNet18 model (`resnet`) is transferred to the appropriate device (`device`), which could be a CPU or GPU, depending on availability and compatibility. This ensures that the model summary reflects the actual computational context in which the model will be used.\n",
    "- **Summary Generation**: The `summary` function is called with the model (`resnet.to(device)`) and a tuple specifying the input size (`(3, 96, 96)`), which represents 3 color channels and a spatial dimension of 96x96 pixels. This input size is tailored to the specific requirements or modifications made to the ResNet18 model to accommodate the different image dimensions from the original ImageNet dataset.\n",
    "\n",
    "### Utility and Implications\n",
    "- **Model Inspection**: The generated summary provides critical insights into the model, including the layers, their types, output dimensions, and the number of trainable parameters. This information is invaluable for debugging, optimizing, and understanding the model's capacity and computational requirements.\n",
    "- **Adaptation to Input Size**: Specifying the input size as `(3, 96, 96)` indicates an adaptation of the ResNet18 model to work with images larger than the standard 224x224 pixels used in ImageNet. This flexibility demonstrates how pre-trained models can be adjusted for various input dimensions, a common requirement in practical applications.\n",
    "\n",
    "The use of `torchsummary` for model inspection exemplifies a practical approach to deep learning model development and analysis, providing clear visibility into the network's architecture and facilitating informed decisions about modifications and optimizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "miH6N6-nIlNI"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(resnet.to(device),(3,96,96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DmEk8JqSsJM"
   },
   "outputs": [],
   "source": [
    "# Freeze all layers (final layer changed later)\n",
    "for p in resnet.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "    # python note: the above operation can be implemented in-line:\n",
    "    #p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVbQK-B-KlQS"
   },
   "outputs": [],
   "source": [
    "# change the final layer\n",
    "resnet.fc = nn.Linear(512,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLj5EhFJLcPa"
   },
   "outputs": [],
   "source": [
    "# push the model to the GPU (if using)\n",
    "resnet.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTt-fBI_IlP_"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WRSghzBIlTB"
   },
   "outputs": [],
   "source": [
    "lossfun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(resnet.parameters(),lr=0.001,momentum=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTU176WWIlV3"
   },
   "outputs": [],
   "source": [
    "numepochs = 10\n",
    "\n",
    "# initialize losses\n",
    "trainLoss = torch.zeros(numepochs)\n",
    "testLoss  = torch.zeros(numepochs)\n",
    "trainAcc  = torch.zeros(numepochs)\n",
    "testAcc   = torch.zeros(numepochs)\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(numepochs):\n",
    "\n",
    "  # loop over training data batches\n",
    "  resnet.train() # switch to train mode\n",
    "  batchLoss = []\n",
    "  batchAcc  = []\n",
    "  for X,y in train_loader:\n",
    "\n",
    "    # push data to GPU\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # forward pass and loss\n",
    "    yHat = resnet(X)\n",
    "    loss = lossfun(yHat,y)\n",
    "\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # loss and accuracy from this batch\n",
    "    batchLoss.append(loss.item())\n",
    "    batchAcc.append( torch.mean((torch.argmax(yHat,axis=1) == y).float()).item() )\n",
    "  # end of batch loop...\n",
    "\n",
    "  # and get average losses and accuracies across the batches\n",
    "  trainLoss[epochi] = np.mean(batchLoss)\n",
    "  trainAcc[epochi]  = 100*np.mean(batchAcc)\n",
    "\n",
    "\n",
    "  #### test performance (here done in batches!)\n",
    "  resnet.eval() # switch to test mode\n",
    "  batchAcc  = []\n",
    "  batchLoss = []\n",
    "  for X,y in test_loader:\n",
    "\n",
    "    # push data to GPU\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # forward pass and loss\n",
    "    with torch.no_grad():\n",
    "      yHat = resnet(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "    \n",
    "    # loss and accuracy from this batch\n",
    "    batchLoss.append(loss.item())\n",
    "    batchAcc.append( torch.mean((torch.argmax(yHat,axis=1) == y).float()).item() )\n",
    "  # end of batch loop...\n",
    "\n",
    "  # and get average losses and accuracies across the batches\n",
    "  testLoss[epochi] = np.mean(batchLoss)\n",
    "  testAcc[epochi]  = 100*np.mean(batchAcc)\n",
    "\n",
    "  # print out a status update\n",
    "  print(f'Finished epoch {epochi+1}/{numepochs}. Test accuracy = {testAcc[epochi]:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPrWLULcL5ne"
   },
   "source": [
    "# Visualize the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ubv4l86NIlYw"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(trainLoss,'s-',label='Train')\n",
    "ax[0].plot(testLoss,'o-',label='Test')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss (MSE)')\n",
    "ax[0].set_title('Model loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(trainAcc,'s-',label='Train')\n",
    "ax[1].plot(testAcc,'o-',label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_title(f'Final model train/test accuracy: {trainAcc[-1]:.2f}/{testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.suptitle('Pretrained ResNet-18 on STL10 data',fontweight='bold',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KF0H8K6L_vm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t968l__2IlbY"
   },
   "outputs": [],
   "source": [
    "# inspect a few random images\n",
    "\n",
    "X,y = next(iter(test_loader))\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "resnet.eval()\n",
    "predictions = torch.argmax( resnet(X) ,axis=1)\n",
    "\n",
    "\n",
    "fig,axs = plt.subplots(4,4,figsize=(10,10))\n",
    "\n",
    "for (i,ax) in enumerate(axs.flatten()):\n",
    "\n",
    "  # extract that image (need to transpose it back to 96x96x3)\n",
    "  pic = X.data[i].cpu().numpy().transpose((1,2,0))\n",
    "  pic = pic-np.min(pic) # undo normalization\n",
    "  pic = pic/np.max(pic)\n",
    "  \n",
    "  # show the image\n",
    "  ax.imshow(pic)\n",
    "  \n",
    "  \n",
    "  # label and true class\n",
    "  label = trainset.classes[predictions[i]]\n",
    "  truec = trainset.classes[y[i]]\n",
    "  title = f'Pred: {label}  -  true: {truec}'\n",
    "\n",
    "  # set the title with color-coded accuracy\n",
    "  titlecolor = 'g' if truec==label else 'r'\n",
    "  ax.text(48,90,title,ha='center',va='top',fontweight='bold',color='k',backgroundcolor=titlecolor,fontsize=8)\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aIlAxsUvIld8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
