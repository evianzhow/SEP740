{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fafzali\\AppData\\Local\\Temp\\ipykernel_31000\\1480152746.py:17: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  display.set_matplotlib_formats('svg')\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# NEW! for importing data\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IBSQO5HB6Kje"
   },
   "outputs": [],
   "source": [
    "# use GPU if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HOkOefftqyg"
   },
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet demonstrates how to download the EMNIST dataset, specifically its letters and digits splits, using PyTorch's `torchvision.datasets` module. The EMNIST dataset extends the original MNIST dataset to include handwritten letters, making it a valuable resource for tasks that require recognizing both digits and letters. Here's how the dataset downloading process is carried out for both subsets:\n",
    "\n",
    "### Dataset Downloading Process\n",
    "- **Letter Dataset**: The `torchvision.datasets.EMNIST` function is called with the `split` parameter set to `'letters'`. This instructs the function to download the letters part of the EMNIST dataset. The `root` parameter specifies the directory (`'emnist'`) where the dataset should be saved, and `download=True` enables the automatic downloading of the data if it's not already present in the specified directory. The downloaded letters dataset is stored in the variable `letterdata`.\n",
    "- **Number Dataset**: Similarly, the digits part of the EMNIST dataset is downloaded by setting the `split` parameter to `'digits'`. The rest of the parameters are identical to the letters dataset download process. The variable `numberdata` holds the downloaded digits dataset.\n",
    "\n",
    "### Utility\n",
    "Downloading both the letters and digits splits of the EMNIST dataset prepares the data for tasks involving the recognition of handwritten characters beyond the original MNIST digits. This capability is especially useful in applications that require a broader understanding of handwritten text, such as automated form processing or educational software that assists in handwriting learning.\n",
    "\n",
    "This straightforward method of accessing and downloading standardized datasets underscores the convenience provided by PyTorch and its accompanying `torchvision` module, facilitating quick setup for machine learning and deep learning experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\fafzali\\appdata\\local\\anaconda3\\lib\\site-packages (0.16.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\fafzali\\appdata\\local\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\fafzali\\appdata\\local\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Collecting torch==2.2.2\n",
      "  Downloading torch-2.2.2-cp310-cp310-win_amd64.whl (198.6 MB)\n",
      "     ------------------------------------- 198.6/198.6 MB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sympy in c:\\users\\fafzali\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.2.2->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\fafzali\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.2.2->torchvision) (2.8.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\fafzali\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.2.2->torchvision) (3.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\fafzali\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.2.2->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\fafzali\\appdata\\local\\anaconda3\\lib\\site-packages (from torch==2.2.2->torchvision) (2022.11.0)\n",
      "Collecting typing-extensions>=4.8.0\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fafzali\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch==2.2.2->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\fafzali\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy->torch==2.2.2->torchvision) (1.2.1)\n",
      "Installing collected packages: typing-extensions, torch, torchvision\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0\n",
      "    Uninstalling torch-2.1.0:\n",
      "      Successfully uninstalled torch-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\fafzali\\\\AppData\\\\Local\\\\anaconda3\\\\Lib\\\\site-packages\\\\~orch\\\\lib\\\\asmjit.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download the file. HTTP status code: 410\n"
     ]
    }
   ],
   "source": [
    "# Import the requests module to handle HTTP requests\n",
    "import requests\n",
    "\n",
    "# The URL from which the EMNIST dataset will be downloaded\n",
    "url = 'https://cloudstor.aarnet.edu.au/plus/s/ZNmuFiuQTqZlu9W/download'\n",
    "\n",
    "# Send a GET request to the specified URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Ensure the request was successful (HTTP status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Open a file in binary write mode. The 'wb' parameter is crucial for binary files.\n",
    "    with open('/mnt/data/emnist.zip', 'wb') as file:\n",
    "        # Write the content of the response to the file.\n",
    "        file.write(response.content)\n",
    "    print(\"Download successful. File saved as '/mnt/data/emnist.zip'.\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. HTTP status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.nist.gov/itl to ./emnist_data/EMNIST\\raw\\gzip.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 112768/112768 [00:00<00:00, 2189737.38it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "File not found or corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EMNIST\n\u001b[1;32m----> 3\u001b[0m emnist \u001b[38;5;241m=\u001b[39m \u001b[43mEMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./emnist_data/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mletters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      5\u001b[0m indexes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(emnist))\n\u001b[0;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(indexes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:297\u001b[0m, in \u001b[0;36mEMNIST.__init__\u001b[1;34m(self, root, split, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_file(split)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_file(split)\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_split_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:99\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:334\u001b[0m, in \u001b[0;36mEMNIST.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    332\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 334\u001b[0m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m gzip_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gzip_file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(gzip_folder):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\utils.py:434\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[0;32m    432\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[1;32m--> 434\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\utils.py:155\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# check integrity of downloaded file\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_integrity(fpath, md5):\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found or corrupted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: File not found or corrupted."
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import EMNIST\n",
    "\n",
    "emnist = EMNIST(root='./emnist_data/', split = 'letters', train=True, transform=None, download=True).data.numpy()\n",
    "\n",
    "indexes = np.arange(len(emnist))\n",
    "np.random.shuffle(indexes)\n",
    "\n",
    "samples = emnist[indexes[:N]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MU7rvmWuhjud"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.nist.gov/itl to Datasets/EMNIST\\EMNIST\\raw\\gzip.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 112768/112768 [00:00<00:00, 1499477.77it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "File not found or corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainset \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDatasets/EMNIST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mletters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m testset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mEMNIST(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasets/EMNIST\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mletters\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:297\u001b[0m, in \u001b[0;36mEMNIST.__init__\u001b[1;34m(self, root, split, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_file(split)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_file(split)\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_split_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:99\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:334\u001b[0m, in \u001b[0;36mEMNIST.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    332\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 334\u001b[0m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m gzip_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gzip_file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(gzip_folder):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\utils.py:434\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[0;32m    432\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[1;32m--> 434\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\utils.py:155\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# check integrity of downloaded file\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_integrity(fpath, md5):\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found or corrupted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: File not found or corrupted."
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.EMNIST(root='Datasets/EMNIST', split='letters', train=True, download=True)\n",
    "testset = torchvision.datasets.EMNIST(root='Datasets/EMNIST', split='letters', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet details the process of applying transformations to the EMNIST letters dataset, preparing it for use with convolutional neural networks (CNNs) in PyTorch. This process includes data cleaning, tensor reshaping, normalization, dataset splitting, and DataLoader creation. Here's a breakdown of each step:\n",
    "\n",
    "### Data Preparation and Transformations\n",
    "- **Removing N/A Class**: The EMNIST dataset includes a placeholder class for 'N/A'. This class is removed by selecting all classes except the first (`letterCategories = letterdata.classes[1:]`) and adjusting the labels accordingly (`labels = copy.deepcopy(letterdata.targets)-1`).\n",
    "\n",
    "- **Tensor Reshaping and Normalization**: The images are reshaped into a 4-dimensional tensor suitable for CNNs, with dimensions representing the batch size, number of channels (1 for grayscale images), and image height and width (28x28 pixels). The data type is also converted from `int8` to `float`, and the pixel values are normalized to a range of `[0, 1]` by dividing by the maximum pixel value in the dataset.\n",
    "\n",
    "### Dataset Splitting\n",
    "- The dataset is split into training and testing sets using `train_test_split`, with 10% of the data reserved for testing. This split allows for the evaluation of the model on unseen data.\n",
    "\n",
    "### DataLoader Creation\n",
    "- **PyTorch Datasets**: The training and testing sets are wrapped into `TensorDataset` objects, pairing the images with their corresponding labels. This encapsulation facilitates the handling of data and labels together.\n",
    "  \n",
    "- **DataLoaders**: DataLoader objects for the training and testing sets are instantiated (`letter_train_loader` and `letter_test_loader`). For the training DataLoader, `batch_size` is set to 32, `shuffle=True` ensures the data is shuffled to promote model generalization, and `drop_last=True` discards the last batch if it contains fewer samples than the specified batch size. The testing DataLoader retrieves the entire test set in a single batch, which is practical for model evaluation purposes.\n",
    "\n",
    "### Utility\n",
    "This procedure showcases a comprehensive approach to dataset preparation for deep learning tasks, emphasizing the importance of data cleaning, normalization, and batching. By converting the EMNIST letters dataset into a format compatible with CNN architectures and organizing it into manageable batches, the code lays the groundwork for efficient model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPJJu-5edsyi"
   },
   "outputs": [],
   "source": [
    "# transformations on the letter data\n",
    "\n",
    "# remove N/A class\n",
    "letterCategories = letterdata.classes[1:]\n",
    "labels = copy.deepcopy(letterdata.targets)-1\n",
    "\n",
    "# transform to 4D tensor for conv layers (and transform from int8 to float)\n",
    "letterImages = letterdata.data.view([letterdata.data.shape[0],1,28,28]).float()\n",
    "letterImages /= torch.max(letterImages)\n",
    "\n",
    "\n",
    "# split the images and convert to dataloaders\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(letterImages, labels, test_size=.1)\n",
    "\n",
    "# convert into PyTorch Datasets\n",
    "train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n",
    "test_data  = torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "# translate into dataloader objects\n",
    "batchsize = 32\n",
    "letter_train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "letter_test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet outlines the process of transforming the EMNIST digits dataset for compatibility with convolutional neural network (CNN) architectures in PyTorch, including dataset splitting and DataLoader creation. This process ensures the data is in the correct format for efficient model training and evaluation. Here’s a step-by-step guide:\n",
    "\n",
    "### Data Transformation for CNNs\n",
    "- **Tensor Reshaping and Normalization**: The digits images are first reshaped into a 4-dimensional tensor suitable for CNNs. This tensor has dimensions indicating the batch size, number of channels (1 for grayscale), and the dimensions of the images (28x28 pixels). The pixel values of the images are converted from `int8` to `float` for processing in neural networks and normalized to a `[0, 1]` range by dividing by the maximum value in the dataset.\n",
    "\n",
    "### Dataset Splitting\n",
    "- **Training and Testing Split**: The reshaped and normalized images are split into training and testing sets using the `train_test_split` function, with 10% of the data allocated for testing. This split facilitates model validation on unseen data, ensuring that the model's performance is robust and generalizable.\n",
    "\n",
    "### DataLoader Creation\n",
    "- **PyTorch Datasets**: Both the training and testing sets are wrapped into `TensorDataset` objects, pairing each image with its corresponding label. This step is crucial for handling the data and labels together efficiently during the training process.\n",
    "  \n",
    "- **DataLoader Objects**: DataLoader instances for the training and testing data (`number_train_loader` and `number_test_loader`) are created with specified batch sizes. For the training DataLoader, `shuffle=True` randomizes the order of the data, promoting model generalization, and `drop_last=True` ensures that all batches have a consistent number of samples by discarding the last incomplete batch. The testing DataLoader is configured to process the entire test set in a single batch, optimizing for evaluation speed and simplicity.\n",
    "\n",
    "### Utility\n",
    "By converting the EMNIST digits dataset into a format that is directly usable by CNNs and organizing it into efficiently manageable batches, this code facilitates straightforward model training, testing, and evaluation. The careful preparation and batching of the dataset exemplify best practices in data preprocessing for deep learning, ensuring that models can learn from and adapt to the data effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_tZ1ymVp0Sf"
   },
   "outputs": [],
   "source": [
    "### transformations on numbers data\n",
    "\n",
    "# transform to 4D tensor for conv layers (and transform from int8 to float)\n",
    "numberImages = numberdata.data.view([numberdata.data.shape[0],1,28,28]).float()\n",
    "numberImages /= torch.max(numberImages)\n",
    "\n",
    "\n",
    "# split the images and convert to dataloaders\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(numberImages, numberdata.targets, test_size=.1)\n",
    "\n",
    "# convert into PyTorch Datasets\n",
    "train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n",
    "test_data  = torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "# translate into dataloader objects\n",
    "batchsize = 32\n",
    "number_train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "number_test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rsf92yfrGoC"
   },
   "outputs": [],
   "source": [
    "# visualize some letters\n",
    "fig,axs = plt.subplots(3,7,figsize=(13,6))\n",
    "\n",
    "# get a batch of letter data\n",
    "X,y = next(iter(letter_train_loader))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  \n",
    "  # extract the image and its target letter\n",
    "  I = np.squeeze( X[i,:,:] )\n",
    "  letter = letterCategories[y[i]]\n",
    "  \n",
    "  # visualize\n",
    "  ax.imshow(I.T,cmap='gray',vmin=0,vmax=1)\n",
    "  ax.set_title('The letter \"%s\"'%letter,fontsize=10)\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbAG-nwFi5BG"
   },
   "outputs": [],
   "source": [
    "# visualize some numbers\n",
    "fig,axs = plt.subplots(3,7,figsize=(13,6))\n",
    "\n",
    "# get a batch of number data\n",
    "X,y = next(iter(number_train_loader))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  \n",
    "  # extract the image and its target letter\n",
    "  I = np.squeeze( X[i,:,:] )\n",
    "  number = y[i].item()\n",
    "  \n",
    "  # visualize\n",
    "  ax.imshow(I.T,cmap='gray',vmin=0,vmax=1)\n",
    "  ax.set_title('The number \"%s\"'%number,fontsize=10)\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OK8Opkhgp0bO"
   },
   "source": [
    "# Create the DL model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code snippet details the creation of a PyTorch neural network model, `emnistnet`, designed for classifying EMNIST dataset images. This model incorporates both convolutional layers for feature extraction and linear layers for classification, making it well-suited for tasks involving image data. Here's an in-depth explanation of its architecture and functionalities:\n",
    "\n",
    "### Model Architecture\n",
    "- **Feature Map Layers**:\n",
    "  - The model begins with two convolutional layers (`self.conv1` and `self.conv2`), each followed by a max-pooling operation to reduce the spatial dimensions by half, and batch normalization to stabilize the learning by normalizing the layer outputs.\n",
    "  - The first convolutional layer expands the input from 1 channel to 6, applying a 3x3 kernel with padding to maintain the spatial dimensions. The second convolutional layer maintains the channel depth at 6, further processing the features.\n",
    "  \n",
    "- **Linear Decision Layers**:\n",
    "  - After feature extraction, the data is flattened and passed through two linear layers (`self.fc1` and `self.fc2`). The first linear layer reduces the dimensionality to 50, and the second maps these features to the 26 output classes corresponding to the letters in the EMNIST letters dataset.\n",
    "  \n",
    "- **Activation Functions**: Leaky ReLU is used after batch normalization in both convolutional blocks and the first linear layer to introduce non-linearity, allowing the model to learn complex patterns.\n",
    "\n",
    "### Forward Pass\n",
    "- The `forward` method defines the data flow through the network. Optional printing controlled by `printtoggle` can provide insights into the tensor shapes at various stages, aiding in understanding the transformation of data through the model.\n",
    "\n",
    "### Model Instantiation, Loss Function, and Optimizer\n",
    "- An instance of the `emnistnet` class is created, equipped with the capability to print tensor sizes during the forward pass if `printtoggle` is set to True.\n",
    "- The model uses cross-entropy loss (`nn.CrossEntropyLoss()`), suitable for multi-class classification tasks.\n",
    "- Adam optimizer is chosen for updating the model parameters, with a learning rate of 0.001, balancing fast learning while avoiding overshooting the minima.\n",
    "\n",
    "### Utility\n",
    "This model demonstrates a structured approach to building convolutional neural networks in PyTorch, tailored for classifying images into multiple categories. By combining convolutional layers for automatic feature extraction with linear layers for decision making, the `emnistnet` provides a solid foundation for tackling image classification problems. This setup showcases best practices in neural network design, including the use of batch normalization and leaky ReLU activation functions to improve training stability and model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JK3OO3tAtZkA"
   },
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def makeTheNet(printtoggle=False):\n",
    "\n",
    "  class emnistnet(nn.Module):\n",
    "    def __init__(self,printtoggle):\n",
    "      super().__init__()\n",
    "      \n",
    "      # print toggle\n",
    "      self.print = printtoggle\n",
    "\n",
    "      ### -------------- feature map layers -------------- ###\n",
    "      # first convolution layer\n",
    "      self.conv1  = nn.Conv2d(1,6,3,padding=1)\n",
    "      self.bnorm1 = nn.BatchNorm2d(6) # input the number of channels in this layer\n",
    "      # output size: (28+2*1-3)/1 + 1 = 28/2 = 14 (/2 b/c maxpool)\n",
    "\n",
    "      # second convolution layer\n",
    "      self.conv2  = nn.Conv2d(6,6,3,padding=1)\n",
    "      self.bnorm2 = nn.BatchNorm2d(6) # input the number of channels in this layer\n",
    "      # output size: (14+2*1-3)/1 + 1 = 14/2 = 7 (/2 b/c maxpool)\n",
    "\n",
    "      \n",
    "      ### -------------- linear decision layers -------------- ###\n",
    "      self.fc1 = nn.Linear(7*7*6,50)\n",
    "      self.fc2 = nn.Linear(50,26)\n",
    "\n",
    "    def forward(self,x):\n",
    "      \n",
    "      if self.print: print(f'Input: {list(x.shape)}')\n",
    "      \n",
    "      # first block: convolution -> maxpool -> batchnorm -> relu\n",
    "      x = F.max_pool2d(self.conv1(x),2)\n",
    "      x = F.leaky_relu(self.bnorm1(x))\n",
    "      if self.print: print(f'First CPR block: {list(x.shape)}')\n",
    "\n",
    "      # second block: convolution -> maxpool -> batchnorm -> relu\n",
    "      x = F.max_pool2d(self.conv2(x),2)\n",
    "      x = F.leaky_relu(self.bnorm2(x))\n",
    "      if self.print: print(f'Second CPR block: {list(x.shape)}')\n",
    "\n",
    "      # reshape for linear layer\n",
    "      nUnits = x.shape.numel()/x.shape[0]\n",
    "      x = x.view(-1,int(nUnits))\n",
    "      if self.print: print(f'Vectorized: {list(x.shape)}')\n",
    "      \n",
    "      # linear layers\n",
    "      x = F.leaky_relu(self.fc1(x))\n",
    "      x = self.fc2(x)\n",
    "      if self.print: print(f'Final output: {list(x.shape)}')\n",
    "\n",
    "      return x\n",
    "\n",
    "  # create the model instance\n",
    "  net = emnistnet(printtoggle)\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(),lr=.001)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvfGQIRGp0ht"
   },
   "source": [
    "# Create a function that trains the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code defines a function, `function2trainTheModel`, to train a given neural network model on specified training data and evaluate its performance on test data across a number of epochs. The function meticulously records both loss and error rates for each epoch, providing a comprehensive view of the model's learning progress and generalization capability. Here's a breakdown of its components:\n",
    "\n",
    "### Model Preparation and Training Loop\n",
    "- **Device Allocation**: The model (`net`) is transferred to a GPU if available (`net.to(device)`), optimizing computational efficiency.\n",
    "- **Initialization**: Arrays for tracking training and test losses (`trainLoss`, `testLoss`) and error rates (`trainErr`, `testErr`) are initialized to zero tensors with lengths equal to the number of epochs (`numepochs`).\n",
    "\n",
    "### Epoch Iteration\n",
    "- For each epoch, the function iterates over batches of data from `train_loader`, performing the following steps:\n",
    "  - **Forward Pass**: The model processes input data (`X`), generating predictions (`yHat`).\n",
    "  - **Loss Calculation**: The loss between the predictions and true labels (`y`) is computed using a predefined loss function (`lossfun`).\n",
    "  - **Backpropagation**: Gradients are calculated and the optimizer updates the model parameters.\n",
    "  - **Metrics Recording**: The loss and error rate for each batch are recorded. The error rate is calculated as the percentage of incorrect predictions.\n",
    "\n",
    "### Test Performance Evaluation\n",
    "- After processing all training batches for an epoch, the model's performance is evaluated on the test dataset (`test_loader`):\n",
    "  - **Model Evaluation Mode**: The model is switched to evaluation mode (`net.eval()`), disabling dropout and batch normalization effects that are specific to training.\n",
    "  - **Loss and Error Calculation**: Loss and error rate on the test dataset are calculated similarly to the training phase but within a `torch.no_grad()` context to prevent gradient computation.\n",
    "  \n",
    "### Metrics Aggregation\n",
    "- At the end of each epoch, average loss and error rate for training batches are stored, along with the loss and error rate from the test dataset.\n",
    "\n",
    "### Function Output\n",
    "- The function returns the recorded training and test losses, error rates, and the trained model. This comprehensive output enables detailed analysis of the model's training progress and its ability to generalize to unseen data.\n",
    "\n",
    "### Utility\n",
    "This training function exemplifies a structured approach to neural network training and evaluation in PyTorch, emphasizing careful monitoring of both loss and accuracy metrics. By including both training and test phases within each epoch, it provides a holistic view of the model's performance, guiding further tuning and improvements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IblJo1NCp0kl"
   },
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def function2trainTheModel(net,optimizer,train_loader,test_loader,numepochs=10):\n",
    "\n",
    "  # send the model to the GPU\n",
    "  net.to(device)\n",
    "\n",
    "  # initialize losses\n",
    "  trainLoss = torch.zeros(numepochs)\n",
    "  testLoss  = torch.zeros(numepochs)\n",
    "  trainErr  = torch.zeros(numepochs)\n",
    "  testErr   = torch.zeros(numepochs)\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    net.train()\n",
    "    batchLoss = []\n",
    "    batchErr  = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # push data to GPU\n",
    "      X = X.to(device)\n",
    "      y = y.to(device)\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss and error from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "      batchErr.append( torch.mean((torch.argmax(yHat,axis=1) != y).float()).item() )\n",
    "    # end of batch loop...\n",
    "\n",
    "    # and get average losses and error rates across the batches\n",
    "    trainLoss[epochi] = np.mean(batchLoss)\n",
    "    trainErr[epochi]  = 100*np.mean(batchErr)\n",
    "\n",
    "\n",
    "\n",
    "    ### test performance\n",
    "    net.eval()\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "\n",
    "    # push data to GPU\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    with torch.no_grad(): # deactivates autograd\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "      \n",
    "    # get loss and error rate from the test batch\n",
    "    testLoss[epochi] = loss.item()\n",
    "    testErr[epochi]  = 100*torch.mean((torch.argmax(yHat,axis=1) != y).float()).item()\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainLoss,testLoss,trainErr,testErr,net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpGm9xdQ27Ob"
   },
   "source": [
    "# Train the model on the letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9pCC1R2p0nu"
   },
   "outputs": [],
   "source": [
    "# create a new model\n",
    "letterNet,lossfun,optimizer = makeTheNet()\n",
    "\n",
    "trainLoss,testLoss,trainErr,testErr,letterNet = function2trainTheModel(\n",
    "                                                letterNet,optimizer,letter_train_loader,letter_test_loader,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHzKOZjnp0qn"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(trainLoss,'s-',label='Train')\n",
    "ax[0].plot(testLoss,'o-',label='Test')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss (MSE)')\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainErr,'s-',label='Train')\n",
    "ax[1].plot(testErr,'o-',label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Error rates (%)')\n",
    "ax[1].set_title(f'Final model test error rate: {testErr[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SnUUHPm7xQE"
   },
   "source": [
    "# Test the model on the number data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KofCVFBIFTCv"
   },
   "outputs": [],
   "source": [
    "# extract X,y from NUMBER test dataloader\n",
    "X,y = next(iter(number_test_loader))\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "letterNet.eval()\n",
    "yHat = letterNet(X)\n",
    "\n",
    "# the test\n",
    "numberAcc = 100*torch.mean((torch.argmax(yHat,axis=1)!=y).float())\n",
    "\n",
    "print(f'numberNet error rate on NUMBER data: {numberAcc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOfUnmus8kps"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXUYzt68JTcH"
   },
   "source": [
    "# Fine-tune the model with one training batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet demonstrates a method for transferring learned weights from one neural network model (`letterNet`) to another (`numberNet`). This technique is commonly used in transfer learning, where a model trained on one task is adapted for a related but distinct task. The code ensures that the target model (`numberNet`) inherits the knowledge encoded in the weights of the source model (`letterNet`). Here’s a detailed overview:\n",
    "\n",
    "### Target Model Creation\n",
    "- **Model Instantiation**: A new model, referred to as `numberNet`, is created using the `makeTheNet()` function. Alongside the model, the function returns a loss function (`lossfun`) and an optimizer (`optimizer`). The `makeTheNet()` function is designed to provide a model suitable for tasks similar to those `letterNet` was trained on, but not necessarily limited to the same exact task.\n",
    "\n",
    "### Weight Transfer Process\n",
    "- **Iterative Weight Copying**: The code iterates over the parameters (weights and biases) of both `numberNet` (target) and `letterNet` (source) simultaneously using the `zip` function. For each pair of corresponding parameters, the weights from the source model are copied to the target model. This copying is performed using `copy.deepcopy()`, ensuring that the original weights are duplicated exactly without being linked to the source model.\n",
    "\n",
    "### Practical Implications and Considerations\n",
    "- **Immediate Application**: After the weight transfer, `numberNet` is immediately enriched with the knowledge gained by `letterNet` during its training process. This can significantly accelerate learning on new tasks, especially if they are closely related to the original task `letterNet` was trained on.\n",
    "- **Flexibility in Transfer Learning**: This approach highlights the flexibility of neural networks in leveraging pre-trained models. By adjusting only the final layers or fine-tuning the transferred weights, `numberNet` can be effectively applied to new domains or tasks.\n",
    "\n",
    "### Ensuring Model Compatibility\n",
    "- It's crucial that `numberNet` and `letterNet` share a compatible architecture, at least in the layers where weights are being transferred. This compatibility ensures that the weight dimensions match, allowing for a successful transfer process.\n",
    "\n",
    "This technique exemplifies the power of transfer learning in machine learning and deep learning, showcasing how pre-existing models can be repurposed to bootstrap performance on new tasks, saving both time and computational resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajhJrKjBLJW9"
   },
   "outputs": [],
   "source": [
    "# create the target model\n",
    "numberNet,lossfun,optimizer = makeTheNet()\n",
    "\n",
    "# then replace all the weights in TARGET model from SOURCE model\n",
    "for target,source in zip(numberNet.named_parameters(),letterNet.named_parameters()):\n",
    "  target[1].data = copy.deepcopy( source[1].data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0MrjTA3TiRn"
   },
   "outputs": [],
   "source": [
    "# check out the network\n",
    "print(numberNet)\n",
    "print(' ')\n",
    "\n",
    "# and the final layer\n",
    "print(numberNet.fc2)\n",
    "\n",
    "# replace the final layer to have 10 outputs instead of 26\n",
    "numberNet.fc2 = nn.Linear(50,10)\n",
    "\n",
    "# and check it again\n",
    "print(' ')\n",
    "print(numberNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLa6Ef80LJaM"
   },
   "outputs": [],
   "source": [
    "# now re-train the network on the numbers data\n",
    "\n",
    "trainLoss,testLoss,trainErr,testErr,numberNet = function2trainTheModel(\n",
    "                                                   numberNet,optimizer,number_train_loader,number_test_loader,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4qbXw7uLJdE"
   },
   "outputs": [],
   "source": [
    "print(f'numberNet TRAIN error rate: {trainErr[-1]:.2f}%')\n",
    "print(f'numberNet TEST error rate: {testErr[-1]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOQJe_rTzmSI"
   },
   "source": [
    "# Try again, only train output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet outlines an advanced application of transfer learning where the weights of a pre-trained neural network model (`letterNet`) are transferred to a new target model (`numberNet2`). After the weight transfer, the architecture of the target model is slightly modified, and certain layers are frozen to prevent their weights from being updated during further training. Here’s an in-depth explanation:\n",
    "\n",
    "### Target Model Creation\n",
    "- **Model Instantiation**: A new model, `numberNet2`, is created using the `makeTheNet()` function, which also returns a loss function (`lossfun`) and an optimizer (`optimizer`). This setup prepares `numberNet2` for subsequent training or fine-tuning.\n",
    "\n",
    "### Weight Transfer Process\n",
    "- **Iterative Weight Copying**: The weights and biases from `letterNet` (source model) are iteratively copied to `numberNet2` (target model) using a loop that iterates over the named parameters of both models. The `copy.deepcopy()` function ensures an exact, deep copy of the weights, preserving the learned features from `letterNet` without linking the two sets of parameters.\n",
    "\n",
    "### Architecture Adjustment\n",
    "- **Output Layer Modification**: The final fully connected layer (`fc2`) of `numberNet2` is redefined to adjust the number of output units to 10, matching the typical requirement for classifying MNIST digits. This modification tailors the model's output to the new task.\n",
    "\n",
    "### Layer Freezing\n",
    "- **Freezing Specific Layers**: Convolutional (`conv`) and batch normalization (`bnorm`) layers in `numberNet2` are frozen by setting `requires_grad` to `False` for their parameters. This action prevents these layers from being updated during further training, which can be beneficial when the transferred features are already well-suited to the new task and only the final layers need fine-tuning.\n",
    "\n",
    "### Utility and Implications\n",
    "- This approach leverages the representational power of `letterNet`, trained on a potentially related task, to jump-start the performance of `numberNet2` on a new task. By freezing certain layers, the model can maintain the generic feature-detecting capabilities of its early layers while adapting its higher-level representations and output layer to the specifics of the new task, such as classifying digits.\n",
    "- Fine-tuning a model in this manner can lead to significant improvements in learning efficiency and model performance, especially when labeled data for the new task is limited.\n",
    "\n",
    "The method exemplified in this code demonstrates a strategic blend of weight transfer, architectural adjustment, and selective parameter freezing—a potent combination for adapting neural networks to new tasks with minimal training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPl_8ajzzrz6"
   },
   "outputs": [],
   "source": [
    "# create the target model\n",
    "numberNet2,lossfun,optimizer = makeTheNet()\n",
    "\n",
    "# then replace all the weights in TARGET model from SOURCE model\n",
    "for target,source in zip(numberNet2.named_parameters(),letterNet.named_parameters()):\n",
    "  target[1].data = copy.deepcopy( source[1].data )\n",
    "\n",
    "# adjust number of output units\n",
    "numberNet2.fc2 = nn.Linear(50,10)\n",
    "\n",
    "# freeze convolution and batch-norm layers\n",
    "for p in numberNet2.named_parameters():\n",
    "  if ('conv' in p[0]) or ('bnorm' in p[0]):\n",
    "    p[1].requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lAFLEtf1M8g"
   },
   "outputs": [],
   "source": [
    "# now re-train the network on the numbers data\n",
    "\n",
    "trainLoss,testLoss,trainErr,testErr,numberNet2 = function2trainTheModel(\n",
    "                                                   numberNet2,optimizer,number_train_loader,number_test_loader,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7B2vgIV1M8u"
   },
   "outputs": [],
   "source": [
    "print(f'numberNet TRAIN error rate: {trainErr[-1]:.2f}%')\n",
    "print(f'numberNet TEST error rate: {testErr[-1]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOrw1DevzurH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP0jw0LrN1eLLkPLO1SeutR",
   "collapsed_sections": [],
   "name": "DUDL_transfer_codeChallenge_letters2numbers.ipynb",
   "provenance": [
    {
     "file_id": "1Gl6z-zdcb8bnpA9yaVQlQkXvEzoeneUJ",
     "timestamp": 1620284167211
    },
    {
     "file_id": "1eA6J6ztxuctVWX6V1s9jV-6kepO7VfC1",
     "timestamp": 1619797471899
    },
    {
     "file_id": "1FcEBC0NAESIlHQkv6_85R-XDUKGE8XbM",
     "timestamp": 1619549043909
    },
    {
     "file_id": "1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW",
     "timestamp": 1617803880910
    },
    {
     "file_id": "15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4",
     "timestamp": 1617737766196
    },
    {
     "file_id": "1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ",
     "timestamp": 1617734878578
    },
    {
     "file_id": "1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j",
     "timestamp": 1617196833019
    },
    {
     "file_id": "1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H",
     "timestamp": 1617124341706
    },
    {
     "file_id": "1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn",
     "timestamp": 1616697516760
    },
    {
     "file_id": "1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg",
     "timestamp": 1616615469755
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
